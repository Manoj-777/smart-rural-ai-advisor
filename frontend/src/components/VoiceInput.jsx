// src/components/VoiceInput.jsx

import { useSpeechRecognition } from '../hooks/useSpeechRecognition';
import { useLanguage } from '../contexts/LanguageContext';

const LISTENING_TEXT = {
    'en-IN': 'Listening...', 'hi-IN': 'рд╕реБрди рд░рд╣рд╛ рд╣реВрдВ...', 'ta-IN': 'роХрпЗроЯрпНроХро┐ро▒родрпБ...',
    'te-IN': 'р░╡р░┐р░Вр░Яр▒Бр░Вр░жр░┐...', 'kn-IN': 'р▓Жр▓▓р▓┐р▓╕р│Бр▓др│Нр▓др▓┐р▓жр│Ж...', 'ml-IN': 'р┤Хр╡Зр╡╛р┤Хр╡Нр┤Хр╡Бр┤ир╡Нр┤ир╡Б...',
    'bn-IN': 'рж╢рзБржиржЫрж┐...', 'mr-IN': 'рдРрдХрдд рдЖрд╣реЗ...', 'gu-IN': 'рк╕рк╛ркВркнрк│рлА рк░рк╣рлНркпрлБркВ ркЫрлЗ...',
    'pa-IN': 'ри╕рйБриг ри░ри┐ри╣ри╛ ри╣ри╛риВ...', 'or-IN': 'рм╢рнБрмгрнБрмЫрм┐...', 'as-IN': 'рж╢рзБржирж┐ ржЖржЫрзЗ...',
    'ur-IN': '╪│┘Ж ╪▒█Б╪з █Б┘И┌║...',
};

function VoiceInput({ language, onTranscript }) {
    const { t } = useLanguage();
    const { isListening, error, startListening, stopListening } = 
        useSpeechRecognition(language, onTranscript);

    const listeningLabel = LISTENING_TEXT[language] || 'Listening...';

    return (
        <div className="voice-input-group">
            <button 
                className={`mic-btn ${isListening ? 'recording' : ''}`}
                onClick={isListening ? stopListening : startListening}
                title={isListening ? (t('voiceStopListening') || 'Stop listening') : (t('voiceClickToSpeak') || 'Click to speak')}
            >
                {isListening ? 'ЁЯФ┤' : 'ЁЯОд'}
            </button>
            {isListening && <span className="voice-status listening">{listeningLabel}</span>}
            {error && <span className="voice-status error">{error}</span>}
        </div>
    );
}

export default VoiceInput;
